{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a44e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score # Confusion matrix 수업 때 진행할 예정\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c815d5",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "- train/test로 나누게 되면 과적합이 발생할 확률이 높다(overfitting)\n",
    "- 과적합은? 모델이 학습 데이터에 과도하게 최적화된다. -> 실제 다른 데이터로 수행하는 경우에는 예측 성능이 과도하게 떨어질 수 있다.\n",
    "- train의 정확도가 높고 test는 낮다.\n",
    "- train은 낮은데 test는 높다? # 문제가 있구나 생각할 것. 과대적합, 과소적합\n",
    "- 이런 부분을 해결하기 위해서 교차검증을 진행한다.\n",
    "- 모의고사 문제를 볼 때 랜덤하게 문제를 풀어본다.\n",
    "- 1~100번 푸는 것보다 1번 풀고 50번 풀고 20번 풀고 이런 랜덤한 배치를 하게 되면 과적합을 피할 수 있다.\n",
    "- 교차검증은 데이터의 편중을 막기위해 여러 개의 별도의 세트로 구성된 학습 데이터와 검증 데이터 세트로 학습과 평가를 수행하는 것\n",
    "- 그 수행결과에 따라 하이퍼파라미터를 튜닝하는 등 모델 최적화를 진행하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4948e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_iris = load_iris()\n",
    "features = fold_iris.data\n",
    "\n",
    "label = fold_iris.target\n",
    "fold_df_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b536195",
   "metadata": {},
   "source": [
    "### 교차검증 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6f00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5) # 내가 n번만큼 폴드 세트별로 정확도를 볼 것인가?, 해당 정확도를 리스트에 담고 평균을 보거나 한다.\n",
    "# 정확도\n",
    "# 정밀도\n",
    "# 재현율\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307afbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001CF803E0F20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold.split(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f26587e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 교차검증 정확도 :1.0, 교차검증 정밀도 :0.0 교차검증 재현율 :0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m n_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(accuracy_score(y_test, fold_pred), \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m precision \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(\u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_pred\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     16\u001b[0m recall \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(recall_score(y_test, fold_pred), \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m 교차검증 정확도 :\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, 교차검증 정밀도 :\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m 교차검증 재현율 :\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_iter, accuracy, precision, recall))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[0;32m   1629\u001b[0m     y_true,\n\u001b[0;32m   1630\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1637\u001b[0m ):\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m \n\u001b[0;32m   1640\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1365\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1364\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1366\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1368\u001b[0m         )\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1370\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1376\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "n_iter = 0 # 5번 진행 예정이니 초기값 0 먼저 지정\n",
    "for train_idx, test_idx in kfold.split(features):\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = label[train_idx], label[test_idx]\n",
    "    \n",
    "    # 학습을 진행\n",
    "    fold_df_clf.fit(X_train, y_train)\n",
    "    \n",
    "    #예측\n",
    "    fold_pred = fold_df_clf.predict(X_test)\n",
    "    \n",
    "    # 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, fold_pred), 3)\n",
    "    precision = np.round(precision_score(y_test, fold_pred), 3)\n",
    "    recall = np.round(recall_score(y_test, fold_pred), 3)\n",
    "    print(\"\\n{} 교차검증 정확도 :{}, 교차검증 정밀도 :{} 교차검증 재현율 :{}\".format(n_iter, accuracy, precision, recall))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "    cv_precision.append(precision)\n",
    "    cv_recall.append(recall)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"\\n 평균 검증 정확도\", np.mean(cv_accuracy), np.mean(cv_precision), np.mean(cv_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e885a1",
   "metadata": {},
   "source": [
    "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6478d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54830b9",
   "metadata": {},
   "source": [
    "- iris 데이터는 타겟이 이진이 아니다.\n",
    "- 0, 1, 2 세 가지로 나눠진다.\n",
    "- recall, precision 얘는 타겟값이 이진이 아니면 계산할 때 문제가 생길 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a178a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 교차검증 정확도 :1.0, 교차검증 정밀도 :0.0 교차검증 재현율 :0.0\n",
      "\n",
      "2 교차검증 정확도 :1.0, 교차검증 정밀도 :0.0 교차검증 재현율 :0.0\n",
      "\n",
      "3 교차검증 정확도 :0.9, 교차검증 정밀도 :0.0 교차검증 재현율 :0.0\n",
      "\n",
      "4 교차검증 정확도 :0.933, 교차검증 정밀도 :0.0 교차검증 재현율 :0.0\n",
      "\n",
      "5 교차검증 정확도 :0.8, 교차검증 정밀도 :0.0 교차검증 재현율 :0.0\n",
      "\n",
      "\n",
      "\n",
      " 평균 검증 정확도 0.9139999999999999\n"
     ]
    }
   ],
   "source": [
    "# 에러가 나지 않도록 하기 위해서는 precision과 recall값을 제외해야함\n",
    "n_iter = 0 # 5번 진행 예정이니 초기값 0 먼저 지정\n",
    "for train_idx, test_idx in kfold.split(features):\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = label[train_idx], label[test_idx]\n",
    "    \n",
    "    # 학습을 진행\n",
    "    fold_df_clf.fit(X_train, y_train)\n",
    "    \n",
    "    #예측\n",
    "    fold_pred = fold_df_clf.predict(X_test)\n",
    "    \n",
    "    # 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, fold_pred), 3)\n",
    "    #precision = np.round(precision_score(y_test, fold_pred), 3)\n",
    "    #recall = np.round(recall_score(y_test, fold_pred), 3)\n",
    "    print(\"\\n{} 교차검증 정확도 :{}, 교차검증 정밀도 :{} 교차검증 재현율 :{}\".format(n_iter, accuracy, precision, recall))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "    #cv_precision.append(precision)\n",
    "    #cv_recall.append(recall)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"\\n 평균 검증 정확도\", np.mean(cv_accuracy))\n",
    "#print(\"\\n 평균 검증 정확도\", np.mean(cv_accuracy), np.mean(cv_precision), np.mean(cv_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7f52c",
   "metadata": {},
   "source": [
    "- kfold의 문제점\n",
    "- 정답비중에 대해서 고르게 나눠지는 게 아니라 랜덤하게 하다보니깐 정답이 0, 1, 2가 있는데, kfold 나눴을 때 0, 1만 포함되거나, 0만 포함되거나, 2만 포함되거나 1, 2만 포함되거나 이런 식으로 데이터가 나눠질 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b134616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold_iris_data = load_iris()\n",
    "kfold_iris_data_df = pd.DataFrame(data=kfold_iris_data.data, columns=kfold_iris_data.feature_names)\n",
    "kfold_iris_data_df[\"target\"] = kfold_iris_data.target\n",
    "print(kfold_iris_data_df[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ef58d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001CF81473350>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kfold의 문제점을 보면\n",
    "kfold_iris = KFold(n_splits=3)\n",
    "kfold_iris.split(kfold_iris_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbaf7f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_iris_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a7e4ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 :1\n",
      "학습 레이블 데이터 분포\n",
      " 1    50\n",
      "2    50\n",
      "Name: target, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 0    50\n",
      "Name: target, dtype: int64\n",
      "교차검증 :2\n",
      "학습 레이블 데이터 분포\n",
      " 0    50\n",
      "2    50\n",
      "Name: target, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 1    50\n",
      "Name: target, dtype: int64\n",
      "교차검증 :3\n",
      "학습 레이블 데이터 분포\n",
      " 0    50\n",
      "1    50\n",
      "Name: target, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 2    50\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cnt_iter = 0\n",
    "for train_idx, test_idx in kfold_iris.split(kfold_iris_data_df):\n",
    "    cnt_iter += 1\n",
    "    label_train = kfold_iris_data_df[\"target\"].iloc[train_idx]\n",
    "    label_test = kfold_iris_data_df[\"target\"].iloc[test_idx]\n",
    "    print(\"교차검증 :{}\".format(cnt_iter))\n",
    "    print(\"학습 레이블 데이터 분포\\n\", label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포\\n\", label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f9290",
   "metadata": {},
   "source": [
    "- kfold를 사용할 때 이진의 경우도 그렇지만, 이진 외 다중 분류 같은 경우는\n",
    "- target의 값을 동일하게 가져가서 kfold 데이터가 한 쪽으로 몰리지 않게 할 수 있다.\n",
    "\n",
    "### StratifiedKfold\n",
    "- 분류 문제에서만 정답에 대한 이슈가 발생할 것. 0, 1 또는 0, 1, 2 분류에 대한 클래스의 불균형은 대부분 범주형 타겟에 나올 것이다.\n",
    "- 회귀 문제와 같은 연속형 변수는 의미가 없다. 회귀 관련 예측할 때는 stratifiedKfold를 쓸 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca5fb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147e27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf_iris = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc8590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 :1\n",
      "학습 레이블 데이터 분포\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: target, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: target, dtype: int64\n",
      "교차검증 :2\n",
      "학습 레이블 데이터 분포\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: target, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: target, dtype: int64\n",
      "교차검증 :3\n",
      "학습 레이블 데이터 분포\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: target, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cnt_iter = 0\n",
    "for train_idx, test_idx in skf_iris.split(kfold_iris_data_df, kfold_iris_data_df[\"target\"]): # 기존 데이터와 Y값도 같이 넣어야함\n",
    "    cnt_iter += 1\n",
    "    label_train = kfold_iris_data_df[\"target\"].iloc[train_idx]\n",
    "    label_test = kfold_iris_data_df[\"target\"].iloc[test_idx]\n",
    "    print(\"교차검증 :{}\".format(cnt_iter))\n",
    "    print(\"학습 레이블 데이터 분포\\n\", label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포\\n\", label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb6c2067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 교차검증 정확도 :0.98, 교차검증 정밀도 :0.981 교차검증 재현율 :0.979\n",
      "\n",
      "2 교차검증 정확도 :0.92, 교차검증 정밀도 :0.919 교차검증 재현율 :0.919\n",
      "\n",
      "3 교차검증 정확도 :0.96, 교차검증 정밀도 :0.961 교차검증 재현율 :0.961\n",
      "\n",
      "\n",
      "\n",
      " 평균 검증 정확도 0.9533333333333333 0.9536666666666666 0.953\n"
     ]
    }
   ],
   "source": [
    "result_skfold = StratifiedKFold(n_splits=3)\n",
    "result_clf = DecisionTreeClassifier(random_state=100)\n",
    "n_iter = 0 # 5번 진행 예정이니 초기값 0 먼저 지정\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "\n",
    "for train_idx, test_idx in result_skfold.split(features, label):\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = label[train_idx], label[test_idx]\n",
    "    \n",
    "    #학습을 진행\n",
    "    result_clf.fit(X_train, y_train)\n",
    "    \n",
    "    #예측\n",
    "    fold_pred = result_clf.predict(X_test)\n",
    "    \n",
    "    #정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, fold_pred), 3)\n",
    "    precision = np.round(precision_score(y_test, fold_pred, average=\"macro\"), 3)\n",
    "    recall = np.round(recall_score(y_test, fold_pred, average=\"macro\"), 3)\n",
    "    print(\"\\n{} 교차검증 정확도 :{}, 교차검증 정밀도 :{} 교차검증 재현율 :{}\".format(n_iter, accuracy, precision, recall))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "    cv_precision.append(precision)\n",
    "    cv_recall.append(recall)\n",
    "    \n",
    "print(\"\\n\")\n",
    "#print(\"\\n 평균 검증 정확도\", np.mean(cv_accuracy))\n",
    "print(\"\\n 평균 검증 정확도\", np.mean(cv_accuracy), np.mean(cv_precision), np.mean(cv_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52ba5e",
   "metadata": {},
   "source": [
    "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
    "\n",
    "- 정답이 2개만 있으면 문제없이 계산할 수 있었는데, 정답이 3개라서 정답 계산하는 식을 바꿔야 한다.\n",
    "- 그 정답식을 바꿔주는 인자가 average, micro, macro, weighted\n",
    "- micro: 전체의 평균\n",
    "- macro: 평균중의 평균\n",
    "- weighted: 가중 평균"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a9ce6",
   "metadata": {},
   "source": [
    "- Kfold를 사용했을 때 불균형에 대한 문제점을 꼭 인지하고, 코드를 작성할 때 진행해주셔야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f6e21",
   "metadata": {},
   "source": [
    "### 필수과제1. kfold, skf를 사용시 average가 총 3개가 나왔다.\n",
    "- micro\n",
    "- macro\n",
    "- weighted\n",
    "\n",
    "- 이 세 개의 차이점을 개념 정리해주시고, 직접 코드로 작성해서 정확도, 정밀도, 재현율이 어떻게 달라지는지 보여주세요!\n",
    "- iris 데이터를 가지고 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449eebc",
   "metadata": {},
   "source": [
    "### 필수과제2\n",
    "- 우리가 모델을 평가하는 지표가 있다.\n",
    "- 정확도, 정밀도, 재현율, f1스코어, roc-curve 등이 있다.\n",
    "- 평가하는 지표가 어떤 식으로 구성되어있는지 개념만 정리해서 제출해주세요!\n",
    "- 코드를 작성할 필요는 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6638924e",
   "metadata": {},
   "source": [
    "### 필수과제3\n",
    "- sales 데이터를 드릴 예정\n",
    "- 해당 sales 데이터 중에서 가장 많이 판매되었던 상품을 1, 2 3, 4까지 라벨링해주시고 해당 라벨링 값을 정답으로 하여\n",
    "- 위에 배운 내용을 복습하는 코드를 작성해주세요!\n",
    "- 해당 데이터는 정답값이 없다. 우리가 정답값을 만들어야한다.\n",
    "\n",
    "- 그 정답값을 만들어서 DecisionTree 모델만 사용하여 진행\n",
    "- skf를 이용해서 동일하게 micro, macro, weighted를 비교하여 정리해주시고\n",
    "- 데이터의 전처리의 경우 시간이 오래 걸릴 수 있으니 최대한 시간 효율 보셔서 진행해주시면 된다.\n",
    "- 다만 데이터 전처리가 없으면 안 됩니다.\n",
    "- 1, 2, 3, 4 외에 나머지 데이터는 0로 해주시고 데이터 전체 삭제하지 마시고 분류해주세요.\n",
    "- 1, 2, 3, 4, 0 라벨값이 생성될 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa0eb44",
   "metadata": {},
   "source": [
    "- 과제에 대한 지정자를 선정하여 네이버 카페에 올려주셔야 합니다.\n",
    "- 자발적으로 제출하고 싶으신 경우는 방법도 알려드립니다.\n",
    "\n",
    "- 팀별과제는 곧 정리하셔서 영상촬영 예정이며, 전처리에 대한 내용을 5~7분 코드 설명하는 영상으로 정리하셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba5206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
