{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4c5eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=156)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# DecisionTree Classifier 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# iris 데이터 가지고 확인해 보기\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.3, random_state=11)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d93372",
   "metadata": {},
   "source": [
    "- 피처에 대한 중요도를 시각화로 보여주기\n",
    "- feature_importance라는 함수를 이용해서 간단하게 출력이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53344ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importance{0} [0.     0.0214 0.5418 0.4368]\n",
      "sepal length (cm):0.000\n",
      "sepal width (cm):0.021\n",
      "petal length (cm):0.542\n",
      "petal width (cm):0.437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# feature importance 추출\n",
    "print(\"feature importance{0}\", format(np.round(dt_clf.feature_importances_, 4)))\n",
    "\n",
    "# 시각화로 매칭을 진행하자\n",
    "for name, value in zip(iris_data.feature_names, dt_clf.feature_importances_):\n",
    "    print(\"{0}:{1:.3f}\".format(name, value))\n",
    "\n",
    "# 시각화로 진행\n",
    "sns.barplot(x=dt_clf.feature_importances_, y=iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76079b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 데이터로 과적합을 살펴보자\n",
    "dt_tt = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b87e1",
   "metadata": {},
   "source": [
    "### 과적합을 시각화를 통해 살펴보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bb0126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7552a31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 존재하지만, 시간 관계상 생략\n",
    "dt_tt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0234737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttsp = dt_tt[[\"survived\",\"pclass\",\"fare\"]] # 2차원 데이터로 시각화를 진행해서 과적합을 보여드리려고 2개만 임의로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b448437e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     fare\n",
       "0           0       3   7.2500\n",
       "1           1       1  71.2833\n",
       "2           1       3   7.9250\n",
       "3           1       1  53.1000\n",
       "4           0       3   8.0500\n",
       "..        ...     ...      ...\n",
       "886         0       2  13.0000\n",
       "887         1       1  30.0000\n",
       "888         0       3  23.4500\n",
       "889         1       1  30.0000\n",
       "890         0       3   7.7500\n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ttsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbd5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Classifier의 Decision Boundary를 시각화하는 함수\n",
    "def visualize_boundary(model, X, y):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # train data scatter plot으로 나타내기\n",
    "    ax.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, s=25, cmap=\"rainbow\", edgecolor=\"k\", \n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis(\"tight\")\n",
    "    ax.axis(\"off\")\n",
    "    xlim_start, xlim_end = ax.get_xlim()\n",
    "    ylim_start, ylim_end = ax.get_ylim()\n",
    "    \n",
    "    # 호출 파라미터로 들어온 train data model 학습\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # meshgrid 형태인 모든 좌표값으로 예측 수행\n",
    "    xx, yy = np.meshgrid(np.linspace(xlim_start, xlim_end, num=200), np.linspace(ylim_start, ylim_end, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    # contourf()를 이용하여 class boundary를 visualization 수행\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3, \n",
    "                           levels=np.arange(n_classes + 1) - 0.5, \n",
    "                           cmap=\"rainbow\", clim=(y.min(), y.max()), zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a9d367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=156)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 진행하기\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_ttsp[[\"pclass\",\"fare\"]], \n",
    "                                                    df_ttsp[\"survived\"], \n",
    "                                                    test_size=0.3, random_state=111)\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8511c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 먼저 저번 시간에 배운 것처럼 튜닝을 하지 않고 바로 진행해보자\n",
    "df_clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "visualize_boundary(dt_clf, df_ttsp[[\"pclass\",\"fare\"]], df_ttsp[\"survived\"])\n",
    "# 전체 데이터에 대해서 시각화..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37bec07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하이퍼파라미터를 조정해서 진행\n",
    "dt_clf1 = DecisionTreeClassifier(max_depth=4, min_samples_split=7, random_state=111).fit(X_train, y_train)\n",
    "visualize_boundary(dt_clf1, df_ttsp[[\"pclass\",\"fare\"]], df_ttsp[\"survived\"])\n",
    "# 전체 데이터에 대해서 시각화..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c49a5",
   "metadata": {},
   "source": [
    "### GridSearchCV를 이용한 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42930fd",
   "metadata": {},
   "source": [
    "- 튜닝 전 베이스 모델 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f9afddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=156)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_ttsp[[\"pclass\",\"fare\"]], \n",
    "                                                    df_ttsp[\"survived\"], \n",
    "                                                    test_size=0.3, random_state=111)\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7eb4e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7014925373134329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = dt_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0666e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "평균 정확도:0.6566\n",
      "최적의 하이퍼파라미터 {'max_depth': 4, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\":[4,8,12,14,20,24], \n",
    "    \"min_samples_split\":[5,10,15,20]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring=\"accuracy\", cv=3, verbose=1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print(\"평균 정확도:{0:.4f}\".format(grid_cv.best_score_))\n",
    "print(\"최적의 하이퍼파라미터\", grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b5c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(grid_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f2f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>7.059039e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 5}</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.690821</td>\n",
       "      <td>0.656556</td>\n",
       "      <td>0.024545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>9.846597e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 10}</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.690821</td>\n",
       "      <td>0.653351</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>2.287190e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 15}</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.690821</td>\n",
       "      <td>0.653351</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>7.867412e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 20}</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.690821</td>\n",
       "      <td>0.653351</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>9.090832e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 5}</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>0.649038</td>\n",
       "      <td>0.657005</td>\n",
       "      <td>0.635668</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>1.707453e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 10}</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.627648</td>\n",
       "      <td>0.023395</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>1.336504e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 15}</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.632432</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>3.024699e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 20}</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.657005</td>\n",
       "      <td>0.626053</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>9.856750e-04</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 5}</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.645346</td>\n",
       "      <td>0.040628</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>2.386652e-04</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 10}</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.671498</td>\n",
       "      <td>0.619666</td>\n",
       "      <td>0.049564</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>4.634676e-04</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 15}</td>\n",
       "      <td>0.620192</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.638866</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>1.854912e-04</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 20}</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.671498</td>\n",
       "      <td>0.634089</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>5.016322e-04</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_split': 5}</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.651756</td>\n",
       "      <td>0.036724</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>8.130009e-04</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_split': 10}</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.671498</td>\n",
       "      <td>0.619666</td>\n",
       "      <td>0.049564</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>6.912193e-05</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_split': 15}</td>\n",
       "      <td>0.620192</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.638866</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>8.232130e-04</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_split': 20}</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.671498</td>\n",
       "      <td>0.634089</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>4.814119e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5}</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.700483</td>\n",
       "      <td>0.653366</td>\n",
       "      <td>0.038668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>7.102699e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10}</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.676329</td>\n",
       "      <td>0.621276</td>\n",
       "      <td>0.051271</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>3.927831e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 15}</td>\n",
       "      <td>0.620192</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.643697</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>2.433695e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 20}</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>0.638920</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>1.973521e-04</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 24, 'min_samples_split': 5}</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.700483</td>\n",
       "      <td>0.653366</td>\n",
       "      <td>0.038668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>1.025326e-03</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 24, 'min_samples_split': 10}</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.676329</td>\n",
       "      <td>0.621276</td>\n",
       "      <td>0.051271</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>4.086374e-05</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 24, 'min_samples_split': 15}</td>\n",
       "      <td>0.620192</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.643697</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>8.510100e-04</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 24, 'min_samples_split': 20}</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>0.638920</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.003320      0.001269         0.001986    7.059039e-04   \n",
       "1        0.003024      0.001723         0.002140    9.846597e-04   \n",
       "2        0.002362      0.000447         0.001013    2.287190e-05   \n",
       "3        0.001661      0.000470         0.000997    7.867412e-07   \n",
       "4        0.002996      0.000842         0.001683    9.090832e-04   \n",
       "5        0.002996      0.000027         0.002211    1.707453e-04   \n",
       "6        0.002070      0.000904         0.002395    1.336504e-03   \n",
       "7        0.004788      0.000221         0.001890    3.024699e-04   \n",
       "8        0.003982      0.000705         0.002686    9.856750e-04   \n",
       "9        0.002688      0.000500         0.001166    2.386652e-04   \n",
       "10       0.002309      0.000699         0.001342    4.634676e-04   \n",
       "11       0.002037      0.000057         0.001093    1.854912e-04   \n",
       "12       0.002532      0.000761         0.001702    5.016322e-04   \n",
       "13       0.003321      0.000189         0.001826    8.130009e-04   \n",
       "14       0.003192      0.000250         0.001045    6.912193e-05   \n",
       "15       0.003159      0.000891         0.002024    8.232130e-04   \n",
       "16       0.003724      0.000515         0.001329    4.814119e-04   \n",
       "17       0.002517      0.000417         0.001496    7.102699e-04   \n",
       "18       0.002787      0.000248         0.001550    3.927831e-04   \n",
       "19       0.001784      0.000607         0.000850    2.433695e-04   \n",
       "20       0.002008      0.000032         0.001141    1.973521e-04   \n",
       "21       0.002672      0.000460         0.002175    1.025326e-03   \n",
       "22       0.002849      0.000648         0.001026    4.086374e-05   \n",
       "23       0.002325      0.000470         0.002051    8.510100e-04   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "0                4                       5   \n",
       "1                4                      10   \n",
       "2                4                      15   \n",
       "3                4                      20   \n",
       "4                8                       5   \n",
       "5                8                      10   \n",
       "6                8                      15   \n",
       "7                8                      20   \n",
       "8               12                       5   \n",
       "9               12                      10   \n",
       "10              12                      15   \n",
       "11              12                      20   \n",
       "12              14                       5   \n",
       "13              14                      10   \n",
       "14              14                      15   \n",
       "15              14                      20   \n",
       "16              20                       5   \n",
       "17              20                      10   \n",
       "18              20                      15   \n",
       "19              20                      20   \n",
       "20              24                       5   \n",
       "21              24                      10   \n",
       "22              24                      15   \n",
       "23              24                      20   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0     {'max_depth': 4, 'min_samples_split': 5}           0.644231   \n",
       "1    {'max_depth': 4, 'min_samples_split': 10}           0.644231   \n",
       "2    {'max_depth': 4, 'min_samples_split': 15}           0.644231   \n",
       "3    {'max_depth': 4, 'min_samples_split': 20}           0.644231   \n",
       "4     {'max_depth': 8, 'min_samples_split': 5}           0.600962   \n",
       "5    {'max_depth': 8, 'min_samples_split': 10}           0.596154   \n",
       "6    {'max_depth': 8, 'min_samples_split': 15}           0.625000   \n",
       "7    {'max_depth': 8, 'min_samples_split': 20}           0.586538   \n",
       "8    {'max_depth': 12, 'min_samples_split': 5}           0.596154   \n",
       "9   {'max_depth': 12, 'min_samples_split': 10}           0.552885   \n",
       "10  {'max_depth': 12, 'min_samples_split': 15}           0.620192   \n",
       "11  {'max_depth': 12, 'min_samples_split': 20}           0.596154   \n",
       "12   {'max_depth': 14, 'min_samples_split': 5}           0.605769   \n",
       "13  {'max_depth': 14, 'min_samples_split': 10}           0.552885   \n",
       "14  {'max_depth': 14, 'min_samples_split': 15}           0.620192   \n",
       "15  {'max_depth': 14, 'min_samples_split': 20}           0.596154   \n",
       "16   {'max_depth': 20, 'min_samples_split': 5}           0.605769   \n",
       "17  {'max_depth': 20, 'min_samples_split': 10}           0.552885   \n",
       "18  {'max_depth': 20, 'min_samples_split': 15}           0.620192   \n",
       "19  {'max_depth': 20, 'min_samples_split': 20}           0.596154   \n",
       "20   {'max_depth': 24, 'min_samples_split': 5}           0.605769   \n",
       "21  {'max_depth': 24, 'min_samples_split': 10}           0.552885   \n",
       "22  {'max_depth': 24, 'min_samples_split': 15}           0.620192   \n",
       "23  {'max_depth': 24, 'min_samples_split': 20}           0.596154   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.634615           0.690821         0.656556        0.024545   \n",
       "1            0.625000           0.690821         0.653351        0.027634   \n",
       "2            0.625000           0.690821         0.653351        0.027634   \n",
       "3            0.625000           0.690821         0.653351        0.027634   \n",
       "4            0.649038           0.657005         0.635668        0.024756   \n",
       "5            0.634615           0.652174         0.627648        0.023395   \n",
       "6            0.634615           0.637681         0.632432        0.005402   \n",
       "7            0.634615           0.657005         0.626053        0.029398   \n",
       "8            0.644231           0.695652         0.645346        0.040628   \n",
       "9            0.634615           0.671498         0.619666        0.049564   \n",
       "10           0.644231           0.652174         0.638866        0.013596   \n",
       "11           0.634615           0.671498         0.634089        0.030761   \n",
       "12           0.653846           0.695652         0.651756        0.036724   \n",
       "13           0.634615           0.671498         0.619666        0.049564   \n",
       "14           0.644231           0.652174         0.638866        0.013596   \n",
       "15           0.634615           0.671498         0.634089        0.030761   \n",
       "16           0.653846           0.700483         0.653366        0.038668   \n",
       "17           0.634615           0.676329         0.621276        0.051271   \n",
       "18           0.644231           0.666667         0.643697        0.018977   \n",
       "19           0.634615           0.685990         0.638920        0.036802   \n",
       "20           0.653846           0.700483         0.653366        0.038668   \n",
       "21           0.634615           0.676329         0.621276        0.051271   \n",
       "22           0.644231           0.666667         0.643697        0.018977   \n",
       "23           0.634615           0.685990         0.638920        0.036802   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 4  \n",
       "2                 4  \n",
       "3                 4  \n",
       "4                15  \n",
       "5                19  \n",
       "6                18  \n",
       "7                20  \n",
       "8                 8  \n",
       "9                23  \n",
       "10               13  \n",
       "11               16  \n",
       "12                7  \n",
       "13               23  \n",
       "14               13  \n",
       "15               16  \n",
       "16                2  \n",
       "17               21  \n",
       "18                9  \n",
       "19               11  \n",
       "20                2  \n",
       "21               21  \n",
       "22                9  \n",
       "23               11  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "059c6774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.656556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.653351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.653351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.653351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.635668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.627648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.632432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.626053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.645346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.619666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.638866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.634089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.651756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0.619666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.638866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0.634089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.653366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.621276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0.643697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.638920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.653366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>0.621276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>0.643697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>0.638920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_split  mean_test_score\n",
       "0                4                       5         0.656556\n",
       "1                4                      10         0.653351\n",
       "2                4                      15         0.653351\n",
       "3                4                      20         0.653351\n",
       "4                8                       5         0.635668\n",
       "5                8                      10         0.627648\n",
       "6                8                      15         0.632432\n",
       "7                8                      20         0.626053\n",
       "8               12                       5         0.645346\n",
       "9               12                      10         0.619666\n",
       "10              12                      15         0.638866\n",
       "11              12                      20         0.634089\n",
       "12              14                       5         0.651756\n",
       "13              14                      10         0.619666\n",
       "14              14                      15         0.638866\n",
       "15              14                      20         0.634089\n",
       "16              20                       5         0.653366\n",
       "17              20                      10         0.621276\n",
       "18              20                      15         0.643697\n",
       "19              20                      20         0.638920\n",
       "20              24                       5         0.653366\n",
       "21              24                      10         0.621276\n",
       "22              24                      15         0.643697\n",
       "23              24                      20         0.638920"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df[[\"param_max_depth\",\"param_min_samples_split\",\"mean_test_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17977d6",
   "metadata": {},
   "source": [
    "### 테스트 데이터를 가지고 실제로 정확도를 판단해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e79f3a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depths=4, min_samples_split=5, 정확도:0.7425373134328358\n",
      "max_depths=8, min_samples_split=10, 정확도:0.7052238805970149\n",
      "max_depths=12, min_samples_split=15, 정확도:0.7089552238805971\n",
      "max_depths=16, min_samples_split=20, 정확도:0.7052238805970149\n"
     ]
    }
   ],
   "source": [
    "max_depth_sel = [4,8,12,16]\n",
    "min_samples_split_sel = [5,10,15,20]\n",
    "\n",
    "for maxde, minsp in zip(max_depth_sel, min_samples_split_sel):\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=maxde, min_samples_split=minsp)\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print(\"max_depths={0}, min_samples_split={1}, 정확도:{2}\".format(maxde, minsp, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f2dba9",
   "metadata": {},
   "source": [
    "- 두 수치가 다른데 어떻게 설명할 수 있을까?\n",
    "- 0.6566 : train\n",
    "- 0.7425373134328358 : test\n",
    "- train이 더 낮고, test가 더 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f02a5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "평균 정확도:0.6566\n",
      "최적의 하이퍼파라미터 {'max_depth': 4, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\":[4,8,12,16], \n",
    "    \"min_samples_split\":[5,10,15,20]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring=\"accuracy\", cv=3, verbose=1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print(\"평균 정확도:{0:.4f}\".format(grid_cv.best_score_))\n",
    "print(\"최적의 하이퍼파라미터\", grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd08613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7425373134328358\n"
     ]
    }
   ],
   "source": [
    "best_df_clf = grid_cv.best_estimator_\n",
    "pred1 = best_df_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe433af",
   "metadata": {},
   "source": [
    "- 과적합에 대해서 필수적으로 꼭 고민하시고\n",
    "- 우리가 배웠던, 교차검증을 왜 해야 하는지?\n",
    "- 우리가 모델 파라미터 튜닝을 왜 해야 하는지?\n",
    "- 물론 좋은 평가지표를 얻을 수도 있지만, 실제로는 과적합이 될 수 있다. 그렇기 때문에 이 부분은 항상 고려해서 모델링을 진행해야 합니다.\n",
    "- 수업시간의 타이타닉 데이터와 dt는 과적합이 되기 너무나 좋은 모델이라서 조금은 설명하기에 오류가 있을 수 있지만, 그래도 기본적인 과적합은 필수적으로 꼭 알아둬야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b12384",
   "metadata": {},
   "source": [
    "### 필수과제 1\n",
    "- 타이타닉 변수들을 바꿔서 시각화 후에 어떤 식으로 과적합이 되는지\n",
    "- 타이타닉 변수 인코딩 등 전처리해서 시각화를 해보시는 것도 추천드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698e380",
   "metadata": {},
   "source": [
    "### 앙상블 (Ensemble Learning)\n",
    "- 조화, 균형\n",
    "- 하나의 모델만 사용하는 것이 아니라 다양한 모델을 사용해서 그 모델의 결과를 바탕으로 가장 최적의 결과를 선정한다.\n",
    "---\n",
    "- 보팅(Voting)\n",
    "- 튜표의 개념\n",
    "- 하드보팅, 소프트 보팅\n",
    "- 타이타닉 데이터를 가지고 -> 로지스틱 회귀, DT, RF 세 가지로 예측을 진행해서 투표를 통해 최적의 모델을 선정하고 값을 구한다.\n",
    "- 어떤 기준으로 선정할 것인가?\n",
    "- 하드보팅, 소프트보팅을 나누는 개념이 된다.\n",
    "\n",
    "\n",
    "- 배깅(Bagging)\n",
    "- 데이터셋을 샘플링하여 여러 개로 나눈 후에 하나의 모델에 학습시키고 예측하여 최적의 값을 구한다.\n",
    "- 보팅, 배깅의 차이라고 한다면 -> 보팅은 여러가지 모델을 사용해서 학습을 하는 반면, 배깅은 데이터셋을 나눠서 진행한다.\n",
    "- 타이타닉 데이터가 891개 있으면, 200개씩 랜덤하게 나눠서 추출하여 DT를 학습시키고 해당 결과물을 가지고 선정하는 것\n",
    "- 배깅의 대표적인 방식이 랜덤 포레스트 알고리즘\n",
    "- 랜덤 포레스트 -> DT와는 다른 점은 바로 배깅이 들어간다는 것\n",
    "- DT는 그냥 데이터를 분할하는 형태였다면, RF는 랜덤하게 데이터를 추출해서 나눈다. dt보다 훨씬 성능 및 과적합에 안정적이다.\n",
    "\n",
    "\n",
    "- 부스팅(Boosting)\n",
    "- xgboost, LGBM, Cat 등등 흔히 말하는 성능이 가장 좋은 대표적인 모델을 말하는데\n",
    "- 얘는 가중치를 부여한다.\n",
    "- 실제 예측값이 틀리면 가중치를 두어서 올바르게 학습할 수 있도록 유도한다.\n",
    "\n",
    "\n",
    "- 스태깅\n",
    "- 예측 결과물을 가지고 다시 학습한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
